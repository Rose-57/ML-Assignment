{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d5c72d-a534-489d-ba21-7643ae342dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95be53c5-ac2b-4cbc-9bd5-87e3b7ee53dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names: ['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "Target Names: ['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Display the feature names and target names\n",
    "features = data.feature_names\n",
    "target = data.target_names\n",
    "print(\"Feature Names:\", features)\n",
    "print(\"Target Names:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cea2bfa-8c4d-4831-b6d2-6dab2ab7d7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data.data,columns=features)\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14b19586-cc7a-4f03-8af4-230d6202d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de715a19-f974-43fc-bb62-4343b0d4363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean after scaling: [-3.16286735e-15 -6.53060890e-15 -7.07889127e-16 -8.79983452e-16\n",
      "  6.13217737e-15 -1.12036918e-15 -4.42138027e-16  9.73249991e-16\n",
      " -1.97167024e-15 -1.45363120e-15 -9.07641468e-16 -8.85349205e-16\n",
      "  1.77367396e-15 -8.29155139e-16 -7.54180940e-16 -3.92187747e-16\n",
      "  7.91789988e-16 -2.73946068e-16 -3.10823423e-16 -3.36676596e-16\n",
      " -2.33322442e-15  1.76367415e-15 -1.19802625e-15  5.04966114e-16\n",
      " -5.21317026e-15 -2.17478837e-15  6.85645643e-16 -1.41265636e-16\n",
      " -2.28956670e-15  2.57517109e-15]\n",
      "Standard deviation after scaling: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Check means and standard deviations of the scaled data\n",
    "print(\"Mean after scaling:\", np.mean(data_scaled, axis=0))\n",
    "print(\"Standard deviation after scaling:\", np.std(data_scaled, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6ea5c-517a-4c52-8c97-580016f08680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Steps for the Breast Cancer Dataset\n",
    "\n",
    "1.Load the Dataset:\n",
    "First we load the breast cancer dataset\n",
    "2.Check for Missing Values:\n",
    "In this dataset there are no missing values\n",
    "3.Feature Scaling:\n",
    "The features in this dataset are on different scales so we apply feature scaling.\n",
    "This process adjusts the data so that each feature has a mean of 0 and a standard deviation of 1\n",
    "Standardization helps the model treat all features equally and makes learning faster and more accurate.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eefba420-6cb7-4fb4-b29b-3bc9c0d9dc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "# Logistic Regression is used to predict if something belongs to one of two categories like yes or no.\n",
    "# It's a simple model and works well when the relationship between the features and the outcome is linear.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c612a70e-55ea-47aa-9171-26d62a77c112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classifier\n",
    "\n",
    "#A Decision Tree is like a flowchart.\n",
    "#For the breast cancer dataset it can clearly separate different tumor types based on feature values\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize and train the Decision Tree model\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(\"Decision Tree Accuracy:\", accuracy_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c719c3b4-1258-4839-8e0f-28049f80e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "#Random Forest is like having many decision trees working together.\n",
    "#Itâ€™s more accurate and reliable than a single decision tree because it reduces the risk of overfitting. It works well for datasets with complex patterns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(\"Random Forest Accuracy:\", accuracy_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e571fa37-5ac5-4190-a310-dffb0f73dd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machine (SVM)\n",
    "#SVM tries to draw a line or boundary that best divides the data into two groups.If the data is complicated, SVM can also use curves to separate the groups.\n",
    "#It's great when the data can be divided into two groups clearly.It works well with high-dimensional data. which is the case with the breast cancer dataset.\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the SVM model\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(\"SVM Accuracy:\", accuracy_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eae81bb-1f42-47a1-9b96-ef1f2422b5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# k-Nearest Neighbors (k-NN)\n",
    "#k-NN looks at the 'k' closest points to a new point and predicts the majority class among them. \n",
    "#For breast cancer similar cell features likely belong to the same class so this method can be effective.\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the k-NN model\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(\"k-NN Accuracy:\", accuracy_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ef35635-9b33-4589-bf6f-a76cf8441401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9737\n",
      "Decision Tree Accuracy: 0.9474\n",
      "Random Forest Accuracy: 0.9649\n",
      "SVM Accuracy: 0.9561\n",
      "k-NN Accuracy: 0.9474\n",
      "\n",
      "Best Performing Model: Logistic Regression with Accuracy: 0.9737\n",
      "Worst Performing Model: Decision Tree with Accuracy: 0.9474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(kernel='linear', random_state=42),\n",
    "    \"k-NN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "# Dictionary to store accuracy of each model\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Train each model, make predictions, and calculate accuracy\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores[model_name] = accuracy\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Identify the best and worst performing models\n",
    "best_model = max(accuracy_scores, key=accuracy_scores.get)\n",
    "worst_model = min(accuracy_scores, key=accuracy_scores.get)\n",
    "\n",
    "print(f\"\\nBest Performing Model: {best_model} with Accuracy: {accuracy_scores[best_model]:.4f}\")\n",
    "print(f\"Worst Performing Model: {worst_model} with Accuracy: {accuracy_scores[worst_model]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269670d9-48d6-4e9a-a883-68edf65003b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
